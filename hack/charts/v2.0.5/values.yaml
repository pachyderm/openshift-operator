# SPDX-FileCopyrightText: Pachyderm, Inc. <info@pachyderm.com>
# SPDX-License-Identifier: Apache-2.0

# Deploy Target configures the storage backend to use and cloud provider
# settings (storage classes, etc). It must be one of GOOGLE, AMAZON,
# MINIO, MICROSOFT, CUSTOM or LOCAL.
deployTarget: "{{ .Spec.Pachd.Storage.Backend }}"

global:
  postgresql:
    # postgresqlUsername is the username to access the pachyderm and dex databases
    postgresqlUsername: "{{ .Spec.Pachd.Postgres.User }}"
    # postgresqlPassword to access the postgresql database.
    # If blank, a value will be generated by the postgres subchart
    # When using autogenerated value for the initial install, it must be pulled from the
    # postgres secret and added to values.yaml for future helm upgrades
    postgresqlPassword: "{{ .Spec.Pachd.Postgres.Password }}"
    # postgresqlDatabase is the database name where pachyderm data will be stored
    postgresqlDatabase: "{{ .Spec.Pachd.Postgres.Database  }}"
    # The postgresql database host to connect to. Defaults to postgres service in subchart
    postgresqlHost: "{{ .Spec.Pachd.Postgres.Host }}"
    # The postgresql database port to connect to. Defaults to postgres server in subchart
    postgresqlPort: "{{ .Spec.Pachd.Postgres.Port }}"
    # postgresqlSSL is the SSL mode to use for connecting to Postgres, for the default local postgres it is disabled
    postgresqlSSL: "{{ .Spec.Pachd.Postgres.SSL }}"
  # imagePullSecrets allow you to pull images from private repositories, these will also be added to pipeline workers
  # https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
  # Example:
  # imagePullSecrets:
  #   - regcred
  imagePullSecrets: []

console:
  # enabled controls whether the console manifests are created or not.
  enabled: false
  image:
    # repository is the image repo to pull from; together with tag it
    # replicates the --console-image & --registry arguments to pachctl
    # deploy.
    repository: "{{ .Spec.Console.Image.Repository }}"
    pullPolicy: "{{ .Spec.Console.Image.PullPolicy }}"
    # tag is the image repo to pull from; together with repository it
    # replicates the --console-image argument to pachctl deploy.
    tag: "{{ .Spec.Console.Image.Tag }}"
  # podLabels specifies labels to add to the console pod.
  podLabels: {}
  # resources specifies the resource request and limits.
  resources: {}
  {{ if .Spec.Console.Resources }}
  resources:
    {{ if .Spec.Console.Resources.Requests }}
    requests:
      {{ range $key, $value := (resources .Spec.Console.Resources.Requests) }}
      "{{ $key }}": "{{ $value }}"
      {{ end }}
    {{ end }}
    {{ if .Spec.Console.Resources.Limits }}
    limits:
      {{ range $key, $value := (resources .Spec.Console.Resources.Limits) }}
      "{{ $key }}": "{{ $value }}"
      {{ end }}
    {{ end }}
  {{ end }}

  config:
    issuerURI: ""
    reactAppRuntimeIssuerURI: ""
    oauthRedirectURI: ""
    oauthClientID: ""
    oauthClientSecret: ""
    graphqlPort: 4000
    oauthPachdClientID: ""
    pachdAddress: "pachd-peer.{{ .ObjectMeta.Namespace }}.svc.cluster.local:30653"

  service:
    # labels specifies labels to add to the console service.
    labels: {}
    # type specifies the Kubernetes type of the console service.
    type: ClusterIP

etcd:
  affinity: {}
  # dynamicNodes sets the number of nodes in the etcd StatefulSet.  It
  # is analogous to the --dynamic-etcd-nodes argument to pachctl
  # deploy.
  dynamicNodes: {{ dynamicNodes .Spec.Etcd.DynamicNodes }}
  image:
    repository: "{{ .Spec.Etcd.Image.Repository }}"
    pullPolicy: "{{ .Spec.Etcd.Image.PullPolicy }}"
    tag: "{{ .Spec.Etcd.Image.Tag }}"
  # podLabels specifies labels to add to the etcd pod.
  podLabels: {}
  # resources specifies the resource request and limits
  resources: {}
  {{ if .Spec.Etcd.Resources }}
  resources:
    {{ if .Spec.Etcd.Resources.Requests }}
    requests:
      {{ range $key, $value := (resources .Spec.Etcd.Resources.Requests) }}
      "{{ $key }}": "{{ $value }}"
      {{ end }}
    {{ end }}
    {{ if .Spec.Etcd.Resources.Limits }}
    limits:
      {{ range $key, $value := (resources .Spec.Etcd.Resources.Limits) }}
      "{{ $key }}": "{{ $value }}"
      {{ end }}
    {{ end }}
  {{ end }}
  # storageClass indicates the etcd should use an existing
  # StorageClass for its storage.  It is analogous to the
  # --etcd-storage-class argument to pachctl deploy.
  # More info for setting up storage classes on various cloud providers:
  # AWS: https://docs.aws.amazon.com/eks/latest/userguide/storage-classes.html
  # GCP: https://cloud.google.com/kubernetes-engine/docs/how-to/persistent-volumes/ssd-pd
  # Azure: https://docs.microsoft.com/en-us/azure/aks/concepts-storage
  storageClass: "{{ .Spec.Etcd.StorageClass }}"
  # storageSize specifies the size of the volume to use for etcd.
  # Recommended Minimum Disk size for Microsoft/Azure: 256Gi  - 1,100 IOPS https://azure.microsoft.com/en-us/pricing/details/managed-disks/
  # Recommended Minimum Disk size for Google/GCP: 50Gi        - 1,500 IOPS https://cloud.google.com/compute/docs/disks/performance
  # Recommended Minimum Disk size for Amazon/AWS: 500Gi (GP2) - 1,500 IOPS https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-volume-types.html
  storageSize: "{{ .Spec.Etcd.StorageSize }}"
  service:
    # annotations specifies annotations to add to the etcd service.
    annotations: {}
    # labels specifies labels to add to the etcd service.
    labels: {}
    # type specifies the Kubernetes type of the etcd service.
    type: ClusterIP

enterpriseServer:
  enabled: false
  affinity: {}
  service:
    type: ClusterIP
  # There are three options for TLS:
  # 1. Disabled
  # 2. Enabled, existingSecret, specify secret name
  # 3. Enabled, newSecret, must specify cert, key and name
  tls:
    enabled: false
    secretName: ""
    newSecret:
      create: false
      crt: ""
      key: ""
  resources: {}
    #limits:
    #  cpu: "1"
    #  memory: "2G"
    #requests:
    #  cpu: "1"
    #  memory: "2G"
  # podLabels specifies labels to add to the pachd pod.
  podLabels: {}
  clusterDeploymentID: ""
  image:
    repository: "{{ .Spec.Pachd.Image.Repository }}"
    pullPolicy: "{{ .Spec.Pachd.Image.PullPolicy }}"
    # tag defaults to the chart’s specified appVersion.
    tag: "{{ .Spec.Pachd.Image.Tag }}"

ingress:
  enabled: false
  annotations: {}
  host: ""
  # There are three options for TLS:
  # 1. Disabled
  # 2. Enabled, existingSecret, specify secret name
  # 3. Enabled, newSecret, must specify cert, key, secretName and set newSecret.create to true
  tls:
    enabled: false
    secretName: ""
    newSecret:
      create: false
      crt: ""
      key: ""

pachd:
  enabled: {{ not .Spec.Pachd.Disable }}
  affinity: {}
  # clusterDeploymentID sets the Pachyderm cluster ID.
  clusterDeploymentID: "{{ .Spec.Pachd.ClusterID }}"
  # goMaxProcs is passed as GOMAXPROCS to the pachd container.
  goMaxProcs: 0
  image:
    repository: "{{ .Spec.Pachd.Image.Repository }}"
    pullPolicy: "{{ .Spec.Pachd.Image.PullPolicy }}"
    # tag defaults to the chart’s specified appVersion.
    # This sets the worker image tag as well (they should be kept in lock step)
    tag: "{{ .Spec.Pachd.Image.Tag }}"
  logLevel: "{{ .Spec.Pachd.LogLevel }}"
  # lokiLogging enables Loki logging if set.
  lokiLogging: {{ .Spec.Pachd.LokiLogging }}
  metrics:
    # enabled sets the METRICS environment variable if set.
    enabled: {{ not .Spec.Pachd.Metrics.Disable }}
    # endpoint should be the URL of the metrics endpoint.
    endpoint: "{{ .Spec.Pachd.Metrics.Endpoint }}"
  # podLabels specifies labels to add to the pachd pod.
  podLabels: {}
  # resources specifies the resource requests and limits
  resources: {}
  {{ if .Spec.Pachd.Resources }}
  resources:
    {{ if .Spec.Pachd.Resources.Requests }}
    requests:
      {{ range $key, $value := (resources .Spec.Pachd.Resources.Requests) }}
      "{{ $key }}": "{{ $value }}"
      {{ end }}
    {{ end }}
    {{ if .Spec.Pachd.Resources.Limits }}
    limits:
      {{ range $key, $value := (resources .Spec.Pachd.Resources.Limits) }}
      "{{ $key }}": "{{ $value }}"
      {{ end }}
    {{ end }}
  {{ end }}
  securityContext:
    enabled: false
  # requireCriticalServersOnly only requires the critical pachd
  # servers to startup and run without errors.  It is analogous to the
  # --require-critical-servers-only argument to pachctl deploy.
  requireCriticalServersOnly: {{ .Spec.Pachd.RequireCriticalServers }}
  # If enabled, External service creates a service which is safe to
  # be exposed externally
  externalService:
    enabled: false
    # (Optional) specify the existing IP Address of the load balancer
    loadBalancerIP: ""
    apiGRPCPort: 30650
    s3GatewayPort: 30600
  service:
    # labels specifies labels to add to the pachd service.
    labels: {}
    # type specifies the Kubernetes type of the pachd service.
    type: "ClusterIP"
    #apiGrpcPort:
    #  expose: true
    #  port: 30650
  enterpriseLicenseKey: "{{ .Spec.EnterpriseLicense }}"
  rootToken: ""
  enterpriseSecret: ""
  oauthClientSecret: ""
  serviceAccount:
    create: true
    additionalAnnotations: {}
    name: "pachyderm" #TODO Set default in helpers / Wire up in templates
  storage:
    # backend configures the storage backend to use.  It must be one
    # of GOOGLE, AMAZON, MINIO, MICROSOFT or LOCAL. This is set automatically
    # if deployTarget is GOOGLE, AMAZON, MICROSOFT, or LOCAL
    backend: "{{ .Spec.Pachd.Storage.Backend }}"
    {{ if eq .Spec.Pachd.Storage.Backend "AMAZON" }}
    amazon:
      # bucket sets the S3 bucket to use.
      bucket: "{{ .Spec.Pachd.Storage.Amazon.Bucket }}"
      # cloudFrontDistribution sets the CloudFront distribution in the
      # storage secrets.  It is analogous to the
      # --cloudfront-distribution argument to pachctl deploy.
      cloudFrontDistribution: "{{ .Spec.Pachd.Storage.Amazon.CloudFrontDistribution }}"
      customEndpoint: "{{ .Spec.Pachd.Storage.Amazon.CustomEndpoint }}"
      # disableSSL disables SSL.  It is analogous to the --disable-ssl
      # argument to pachctl deploy.
      disableSSL: {{ .Spec.Pachd.Storage.Amazon.DisableSSL }}
      # id sets the Amazon access key ID to use.  Together with secret
      # and token, it implements the functionality of the
      # --credentials argument to pachctl deploy.
      id: "{{ .Spec.Pachd.Storage.Amazon.ID }}"
      # logOptions sets various log options in Pachyderm’s internal S3
      # client.  Comma-separated list containing zero or more of:
      # 'Debug', 'Signing', 'HTTPBody', 'RequestRetries',
      # 'RequestErrors', 'EventStreamBody', or 'all'
      # (case-insensitive).  See 'AWS SDK for Go' docs for details.
      # logOptions is analogous to the --obj-log-options argument to
      # pachctl deploy.
      logOptions: "{{ .Spec.Pachd.Storage.Amazon.LogOptions }}"
      # maxUploadParts sets the maximum number of upload parts.  It is
      # analogous to the --max-upload-parts argument to pachctl
      # deploy.
      maxUploadParts: {{ .Spec.Pachd.Storage.Amazon.MaxUploadParts }}
      # verifySSL performs SSL certificate verification.  It is the
      # inverse of the --no-verify-ssl argument to pachctl deploy.
      verifySSL: {{ .Spec.Pachd.Storage.Amazon.VerifySSL }}
      # partSize sets the part size for object storage uploads.  It is
      # analogous to the --part-size argument to pachctl deploy.  It
      # has to be a string due to Helm and YAML parsing integers as
      # floats.  Cf. https://github.com/helm/helm/issues/1707
      partSize: "{{ .Spec.Pachd.Storage.Amazon.PartSize }}"
      # region sets the AWS region to use.
      region: "{{ .Spec.Pachd.Storage.Amazon.Region }}"
      # retries sets the number of retries for object storage
      # requests.  It is analogous to the --retries argument to
      # pachctl deploy.
      retries: {{ .Spec.Pachd.Storage.Amazon.Retries }}
      # reverse reverses object storage paths.  It is analogous to the
      # --reverse argument to pachctl deploy.
      reverse: {{ .Spec.Pachd.Storage.Amazon.Reverse }}
      # secret sets the Amazon secret access key to use.  Together with id
      # and token, it implements the functionality of the
      # --credentials argument to pachctl deploy.
      secret: "{{ .Spec.Pachd.Storage.Amazon.Secret }}"
      # timeout sets the timeout for object storage requests.  It is
      # analogous to the --timeout argument to pachctl deploy.
      timeout: "{{ .Spec.Pachd.Storage.Amazon.Timeout }}"
      # token optionally sets the Amazon token to use.  Together with
      # id and secret, it implements the functionality of the
      # --credentials argument to pachctl deploy.
      token: "{{ .Spec.Pachd.Storage.Amazon.Token }}"
      # uploadACL sets the upload ACL for object storage uploads.  It
      # is analogous to the --upload-acl argument to pachctl deploy.
      uploadACL: "{{ .Spec.Pachd.Storage.Amazon.UploadACL }}"
      {{ end }}
      {{ if eq .Spec.Pachd.Storage.Backend "GOOGLE" }}
    google:
      bucket: "{{ .Spec.Pachd.Storage.Google.Bucket }}"
      # cred is a string containing a GCP service account private key,
      # in object (JSON or YAML) form.  A simple way to pass this on
      # the command line is with the set-file flag, e.g.:
      #
      #  helm install pachd -f my-values.yaml --set-file storage.google.cred=creds.json pachyderm/pachyderm
      cred: "{{ .Spec.Pachd.Storage.Google.CredentialSecret }}"
      # Example:
      # cred: |
      #  {
      #    "type": "service_account",
      #    "project_id": "…",
      #    "private_key_id": "…",
      #    "private_key": "-----BEGIN PRIVATE KEY-----\n…\n-----END PRIVATE KEY-----\n",
      #    "client_email": "…@….iam.gserviceaccount.com",
      #    "client_id": "…",
      #    "auth_uri": "https://accounts.google.com/o/oauth2/auth",
      #    "token_uri": "https://oauth2.googleapis.com/token",
      #    "auth_provider_x509_cert_url": "https://www.googleapis.com/oauth2/v1/certs",
      #    "client_x509_cert_url": "https://www.googleapis.com/robot/v1/metadata/x509/…%40….iam.gserviceaccount.com"
      #  }
    {{ end }}
    {{ if eq .Spec.Pachd.Storage.Backend "LOCAL" }}
    local:
      # hostPath indicates the path on the host where the PFS metadata
      # will be stored.  It must end in /.  It is analogous to the
      # --host-path argument to pachctl deploy.
      hostPath: "{{ .Spec.Pachd.Storage.Local.HostPath }}"
      requireRoot: true #Root required for hostpath, but we run rootless in CI
    {{ end }}
    {{ if eq .Spec.Pachd.Storage.Backend "MICROSOFT" }}
    microsoft:
      container: "{{ .Spec.Pachd.Storage.Microsoft.Container }}"
      id: "{{ .Spec.Pachd.Storage.Microsoft.ID }}"
      secret: "{{ .Spec.Pachd.Storage.Microsoft.Secret }}"
    {{ end }}
    {{ if eq .Spec.Pachd.Storage.Backend "MINIO" }}
    minio:
      bucket: "{{ .Spec.Pachd.Storage.Minio.Bucket }}"
      endpoint: "{{ .Spec.Pachd.Storage.Minio.Endpoint }}"
      id: "{{ .Spec.Pachd.Storage.Minio.ID }}"
      secret: "{{ .Spec.Pachd.Storage.Minio.Secret }}"
      secure: "{{ .Spec.Pachd.Storage.Minio.Secure }}"
      signature: "{{ .Spec.Pachd.Storage.Minio.Signature }}"
    {{ end }}
    # putFileConcurrencyLimit sets the maximum number of files to
    # upload or fetch from remote sources (HTTP, blob storage) using
    # PutFile concurrently.  It is analogous to the
    # --put-file-concurrency-limit argument to pachctl deploy.
    putFileConcurrencyLimit: {{ .Spec.Pachd.Storage.PutFileConcurrencyLimit }}
    # uploadConcurrencyLimit sets the maximum number of concurrent
    # object storage uploads per Pachd instance.  It is analogous to
    # the --upload-concurrency-limit argument to pachctl deploy.
    uploadConcurrencyLimit: {{ .Spec.Pachd.Storage.PutFileConcurrencyLimit }}
  ppsWorkerGRPCPort: {{ .Spec.Pachd.PPSWorkerGRPCPort }}
  # There are three options for TLS:
  # 1. Disabled
  # 2. Enabled, existingSecret, specify secret name
  # 3. Enabled, newSecret, must specify cert, key and name
  tls:
    enabled: false
    secretName: ""
    newSecret:
      create: false
      crt: ""
      key: ""
  worker:
    image:
      repository: "{{ .Spec.Worker.Image.Repository }}"
      pullPolicy: "{{ .Spec.Worker.Image.PullPolicy }}"
      # Worker tag is set under pachd.image.tag (they should be kept in lock step)
    serviceAccount:
      create: true
      additionalAnnotations: {}
      # name sets the name of the worker service account.  Analogous to
      # the --worker-service-account argument to pachctl deploy.
      name: "pachyderm-worker" #TODO Set default in helpers / Wire up in templates
  rbac:
    # create indicates whether RBAC resources should be created.
    # Setting it to false is analogous to passing --no-rbac to pachctl
    # deploy.
    create: true
    # clusterRBAC indicates that ClusterRole and ClusterRoleBinding
    # should be used rather than Role and RoleBinding; it is the inverse
    # of --local-roles passed to pachctl deploy.
    clusterRBAC: true



pgbouncer:
  service:
    type: ClusterIP
  resources: {}
    #limits:
    #  cpu: "1"
    #  memory: "2G"
    #requests:
    #  cpu: "1"
    #  memory: "2G"

# Note: Postgres values control the Bitnami Postgresql Subchart
postgresql:
  # enabled controls whether to install postgres or not.
  # If not using the built in Postgres, you must specify a Postgresql
  # database server to connect to in global.postgresql
  # The enabled value is watched by the 'condition' set on the Postgresql
  # dependency in Chart.yaml
  enabled: {{ not .Spec.Postgres.Disable }}
  image:
    tag: "13.3.0"
  initdbScripts:
    dex.sh: |
      #!/bin/bash
      set -e
      psql -v ON_ERROR_STOP=1 --username "$POSTGRES_USER" --dbname "$POSTGRES_DB" <<-EOSQL
        CREATE DATABASE dex;
        GRANT ALL PRIVILEGES ON DATABASE dex TO "$POSTGRES_USER";
      EOSQL
  fullnameOverride: postgres
  persistence:
    # Specify the storage class for the postgresql Persistent Volume (PV)
    # See notes in Bitnami chart values.yaml file for more information.
    # More info for setting up storage classes on various cloud providers:
    # AWS: https://docs.aws.amazon.com/eks/latest/userguide/storage-classes.html
    # GCP: https://cloud.google.com/kubernetes-engine/docs/how-to/persistent-volumes/ssd-pd
    # Azure: https://docs.microsoft.com/en-us/azure/aks/concepts-storage
    storageClass: ""

    # storageSize specifies the size of the volume to use for postgresql
    # Recommended Minimum Disk size for Microsoft/Azure: 256Gi  - 1,100 IOPS https://azure.microsoft.com/en-us/pricing/details/managed-disks/
    # Recommended Minimum Disk size for Google/GCP: 50Gi        - 1,500 IOPS https://cloud.google.com/compute/docs/disks/performance
    # Recommended Minimum Disk size for Amazon/AWS: 500Gi (GP2) - 1,500 IOPS https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-volume-types.html
    size: 10Gi
    labels:
      suite: pachyderm

cloudsqlAuthProxy:
  # connectionName may be found by running `gcloud sql instances describe INSTANCE_NAME --project PROJECT_ID`
  connectionName: ""
  serviceAccount: ""
  port: 5432
  enabled: false
  image:
    # repository is the image repo to pull from; together with tag it
    # replicates the --dash-image & --registry arguments to pachctl
    # deploy.
    repository: "gcr.io/cloudsql-docker/gce-proxy"
    pullPolicy: "{{ .Spec.Etcd.Image.PullPolicy }}"
    # tag is the image repo to pull from; together with repository it
    # replicates the --dash-image argument to pachctl deploy.
    tag: "1.23.0"
  # podLabels specifies labels to add to the dash pod.
  podLabels: {}
  # resources specifies the resource request and limits.
  resources: {}
  # requests:
    #   The proxy's memory use scales linearly with the number of active
    #   connections. Fewer open connections will use less memory. Adjust
    #   this value based on your application's requirements.
    # memory: ""
    #   The proxy's CPU use scales linearly with the amount of IO between
    #   the database and the application. Adjust this value based on your
    #   application's requirements.
    # cpu: ""
  service:
    # labels specifies labels to add to the cloudsql auth proxy service.
    labels: {}
    # type specifies the Kubernetes type of the cloudsql auth proxy service.
    type: ClusterIP
